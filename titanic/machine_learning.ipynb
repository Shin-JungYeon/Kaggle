{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 357명 중 82.913% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=5, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=True, random_state=10, verbose=0,\n",
      "                       warm_start=False)\n",
      "총 357명 중 82.913% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "총 357명 중 79.832% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "총 357명 중 81.513% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "총 357명 중 75.910% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "총 357명 중 73.389% 정확도로 생존을 맞춤\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "총 357명 중 76.471% 정확도로 생존을 맞춤\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 알고리즘 적용\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r'C:\\Users\\ssjy1\\kaggle\\datasets\\datasets_titanic_train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\ssjy1\\kaggle\\datasets\\datasets_titanic_test.csv')\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # Sex\n",
    "    df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "    # Embarked\n",
    "    df.Embarked.fillna('S', inplace=True)\n",
    "    df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "    # Title - 이름으로 호칭 추출.\n",
    "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.')  # 공백으로 시작하고 .으로 끝나는 문자열 추출\n",
    "    df['Title'] = df['Title'].replace(['Capt', 'Col', 'Countess', 'Don','Dona', 'Dr', 'Jonkheer', 'Lady','Major', 'Rev', 'Sir'], 'Other')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs':3, 'Other':4})\n",
    "\n",
    "    # Age - 8개 구간으로 분리하여 카테고리화. 결측치는 호칭의 평균값으로 채움.\n",
    "    meanAge = df[['Title', 'Age']].groupby(['Title']).mean()  # 그룹별 나이의 평균치\n",
    "    for index, row in meanAge.iterrows():\n",
    "        nullIndex = df[(df.Title == index) & (df.Age.isnull())].index\n",
    "        df.loc[nullIndex, 'Age'] = row[0]  # null data에 나이 평균치 임의 입력\n",
    "\n",
    "    df['AgeCategory'] = pd.qcut(df.Age, 8, labels=range(1, 9))  # 동일 갯수로 나누기 범주 만들기\n",
    "    df.AgeCategory = df.AgeCategory.astype(int)\n",
    "\n",
    "    # Cabin - 방번호의 첫 글자만 따서 카테고리화. 결측치는 N으로 채움.\n",
    "    df.Cabin.fillna('N', inplace=True)\n",
    "    df[\"CabinCategory\"] = df[\"Cabin\"].str.slice(start=0, stop=1)\n",
    "    df[\"CabinCategory\"] = df['CabinCategory'].map({ \"N\": 0, \"C\": 1, \"B\": 2, \"D\": 3, \"E\": 4, \"A\": 5, \"F\": 6, \"G\": 7, \"T\": 8 })\n",
    "\n",
    "    # Fare - 운임을 8개의 구간으로 분리하여 카테고리화. 결측치는 0으로 채움.\n",
    "    df.Fare.fillna(0, inplace=True)\n",
    "    df['FareCategory'] = pd.qcut(df.Fare, 8, labels=range(1, 9))\n",
    "    df.FareCategory = df.FareCategory.astype(int)\n",
    "\n",
    "    # SibSp, Parch - 가족으로 합치고, 혼자 탑승한 고객 정보 추출.\n",
    "    df['Family'] = df['SibSp'] + df['Parch'] + 1  # 가족 수 + 본인\n",
    "    df.loc[df[\"Family\"] > 4, \"Family\"] = 5  # 5명 이상은 전부 5\n",
    "\n",
    "    df['IsAlone'] = 1\n",
    "    df.loc[df['Family'] > 1, 'IsAlone'] = 0  # 한 명 이상은 isAlone이 false\n",
    "\n",
    "    # Ticket - 티켓 번호의 첫 번째 번호만 추출하여 카테고리화.\n",
    "    df['TicketCategory'] = df.Ticket.str.split()\n",
    "    df['TicketCategory'] = [i[-1][0] for i in df['TicketCategory']]\n",
    "    df['TicketCategory'] = df['TicketCategory'].replace(['8', '9', 'L'], '8')\n",
    "    df['TicketCategory'] = pd.factorize(df['TicketCategory'])[0] + 1\n",
    "\n",
    "    # axis=1 : 컬럼 삭제. axis=0 : 로우 삭제.\n",
    "    # inplace=True : drop한 후의 데이터프레임으로 기존 데이터프레임을 대체.\n",
    "    df.drop(['PassengerId', 'Ticket', 'Cabin', 'Fare', 'Name', 'Age', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = feature_engineering(train)\n",
    "test = feature_engineering(test)\n",
    "\n",
    "\n",
    "\n",
    "# ========== machine learning - 랜덤 포레스트 검증 1 ==========\n",
    "#  Pclass, Sex, Embarked, Title, AgeCategory, CabinCategory, FareCategory, Family, IsAlone, TicketCategory \n",
    "data = train.drop('Survived', axis=1).values\n",
    "# Survived\n",
    "target = train['Survived'].values\n",
    "\n",
    "# test_size: 분리 비율 설정. \n",
    "# stratify: 분리 기준이 될 데이터 \n",
    "# random_state: 랜덤 seed\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target, test_size=0.4, stratify=target, random_state=0)\n",
    "\n",
    "# n_estimators=50 : 트리 갯수\n",
    "rf = RandomForestClassifier(n_estimators=50, criterion=\"entropy\", max_depth=5, oob_score=True, random_state=10)\n",
    "rf.fit(x_train, y_train)\n",
    "prediction = rf.predict(x_valid)\n",
    "\n",
    "length = y_valid.shape[0]\n",
    "accuracy = accuracy_score(prediction, y_valid)\n",
    "print(f'총 {length}명 중 {accuracy * 100:.3f}% 정확도로 생존을 맞춤')\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# ========== machine learning - 알고리즘 적용 ==========\n",
    "\n",
    "# 지도학습 모델 import - 입력에 대한 결과값이 있어 이를 학습하고, 새로운 데이터에 대한 결과 예측.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data 분리 \n",
    "data = train.drop('Survived', axis=1).values\n",
    "target = train['Survived'].values\n",
    "# test_size: 분리 비율 설정. default=0.25\n",
    "# stratify: 분리 기준이 될 데이터. default=None\n",
    "# random_state: 랜덤 seed\n",
    "# shuffle : split 해주기 전에 섞을 지 여부. default=True\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, target, test_size=0.4, stratify=target, random_state=0)\n",
    "\n",
    "# 모델 적용 함수 \n",
    "def ml_fit(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_valid)\n",
    "    accuracy = accuracy_score(prediction, y_valid) # 전체 샘플 중 맞게 예측한 샘플 수의 비율\n",
    "    print(model)\n",
    "    print(f'총 {y_valid.shape[0]}명 중 {accuracy * 100:.3f}% 정확도로 생존을 맞춤')\n",
    "    print('\\n')\n",
    "    return model\n",
    "\n",
    "# 기본 설정으로만 테스트 \n",
    "#model = ml_fit(RandomForestClassifier(n_estimators=100))\n",
    "model = ml_fit(RandomForestClassifier(n_estimators=50, criterion=\"entropy\", max_depth=5, oob_score=True, random_state=10))\n",
    "model = ml_fit(LogisticRegression(solver='lbfgs'))\n",
    "model = ml_fit(SVC(gamma='scale'))\n",
    "model = ml_fit(KNeighborsClassifier())\n",
    "model = ml_fit(GaussianNB())\n",
    "model = ml_fit(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
