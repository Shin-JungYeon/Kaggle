{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "선형회귀분석:  0.6092200214592733\n",
      "로지스틱스 회귀분석:  0.9020979020979021\n",
      "나이브 베이즈:  0.8951048951048951\n",
      "의사결정나무:  0.8671328671328671\n",
      "서포트 벡터 머신:  0.9020979020979021\n",
      "랜덤포레스트:  0.8881118881118881\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                       # 기초 수학 연산 및 행렬계산\n",
    "import pandas as pd                                      # 데이터프레임 사용\n",
    "from sklearn import datasets                             # iris와 같은 내장 데이터 사용\n",
    "\n",
    "from sklearn.model_selection import train_test_split     # train, test 데이터 분할\n",
    "\n",
    "from sklearn.linear_model import LinearRegression       # 선형 회귀분석\n",
    "from sklearn.linear_model import LogisticRegression     # 로지스틱 회귀분석\n",
    "from sklearn.naive_bayes import GaussianNB               # 나이브 베이즈\n",
    "from sklearn import svm                                  # 서포트 벡터 머신\n",
    "from sklearn import tree                                 # 의사결정나무\n",
    "from sklearn.ensemble import RandomForestClassifier      # 랜덤포레스트\n",
    "\n",
    "import matplotlib.pyplot as plt                          # plot 그릴 때 사용\n",
    "\n",
    "from sklearn.datasets import make_classification         # 분류용 가상 데이터 만들기\n",
    "\n",
    "X, Y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0)\n",
    "\n",
    "raw = datasets.load_breast_cancer()         # sklearn에 내장된 원본 데이터 불러오기\n",
    "print(raw.feature_names)                    # 열(column) 이름 확인\n",
    "\n",
    "data = pd.DataFrame(raw.data)               # 독립변수 데이터 모음  \n",
    "target = pd.DataFrame(raw.target)           # 종속변수 데이터 모음\n",
    "rawData = pd.concat([data,target], axis=1)  # 독립변수 + 종속변수 열 결합\n",
    "\n",
    "# 열(column)이름 설정\n",
    "rawData.columns=['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    " 'mean smoothness', 'mean compactness', 'mean concavity',\n",
    " 'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    " 'radius error', 'texture error', 'perimeter error', 'area error',\n",
    " 'smoothness error', 'compactness error', 'concavity error',\n",
    " 'concave points error', 'symmetry error', 'fractal dimension error',\n",
    " 'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    " 'worst smoothness', 'worst compactness', 'worst concavity',\n",
    " 'worst concave points', 'worst symmetry', 'worst fractal dimension'\n",
    " , 'cancer']\n",
    "\n",
    "rawData.head(10)                                # 데이터 확인\n",
    "\n",
    "x = rawData[['mean radius', 'mean texture']]\n",
    "y = rawData['cancer']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=0)\n",
    "\n",
    "# 대부분의 모델에서 공통으로 제공되는 api\n",
    "'''\n",
    "fit(x_train, y_train)     ## 모수 추정(estimat)\n",
    "get_params()              ## 추정된 모수 확인\n",
    "predict(x_test)           ## x_test로부터 라벨 예측\n",
    "predict_log_proba(x_test) ## 로그 취한 확률 예측\n",
    "predict_proba(x_test)     ## 각 라벨로 예측될 확률\n",
    "score(x_test, y_test)     ## 모델 정확도 평가를 위한 mean accuracy\n",
    "'''\n",
    "\n",
    "# 선형회귀분석\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "clf.coef_\n",
    "clf.intercept_\n",
    "clf.predict(x_test)\n",
    "print('선형회귀분석: ', clf.score(x_test, y_test))\n",
    "\n",
    "# 로지스틱스 회귀분석\n",
    "clf = LogisticRegression(solver='lbfgs').fit(x_train,y_train)\n",
    "clf.predict(x_test)\n",
    "clf.predict_proba(x_test)\n",
    "print('로지스틱스 회귀분석: ', clf.score(x_test,y_test))\n",
    "\n",
    "# 나이브 베이즈\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb.predict(x_test)\n",
    "print('나이브 베이즈: ', gnb.score(x_test, y_test))\n",
    "\n",
    "# 의사결정나무\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)\n",
    "clf.predict_proba(x_test)\n",
    "print('의사결정나무: ', clf.score(x_test, y_test))\n",
    "\n",
    "# 서포트 벡터 머신\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)\n",
    "print('서포트 벡터 머신: ', clf.score(x_test, y_test))\n",
    "\n",
    "# 랜덤포레스트\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.feature_importances_\n",
    "clf.predict(x_test)\n",
    "print('랜덤포레스트: ', clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
